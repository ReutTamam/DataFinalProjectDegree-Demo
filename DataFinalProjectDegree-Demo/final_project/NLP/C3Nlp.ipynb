{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d8e6a1-c7ae-4f53-9204-1768485234a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheets: ['Sheet1']\n",
      "Shape: (7738, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>××¡×¤×¨ ××˜×•×¤×œ ×¨× ×“×•××œ×™</th>\n",
       "      <th>××¡×¤×¨ ××§×¨×” ××©×¤×•×– ×¨× ×“×•××œ×™</th>\n",
       "      <th>× ×§×‘×”</th>\n",
       "      <th>×’×™×œ ××©×¤×•×–</th>\n",
       "      <th>××¦×‘ ××©×¤×—×ª×™_×’×¨×•×©/×”</th>\n",
       "      <th>××¦×‘ ××©×¤×—×ª×™_× ×©×•×™/×</th>\n",
       "      <th>××¦×‘ ××©×¤×—×ª×™_×¨×•×•×§/×”</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_×‘×™×ª ×—×•×œ×™×</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_×’×•×¨××™ ××©×¤×˜ ×•×‘×™×˜×—×•×Ÿ</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_××•×¡×“ ×¨×¤×•××™ ××—×¨</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_×¤× ×™×” ×¢×¦××™×ª</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_×¤×¡×™×›×™××˜×¨ ××—×•×–×™</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_×˜×™×¤×•×œ ××¨×¤××ª×™</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_××•×¡×“×•×ª</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_××¨×¤××” ×¤×¡×™×›×™××˜×¨×™×ª</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_×¨×•×¤× ××˜×¤×œ</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_×¨×™×§</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×¡×˜×˜×•×¡ ×—×•×§×™_××©×¤×•×– ×‘×”×¡×›××”</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×¡×˜×˜×•×¡ ×—×•×§×™_××©×¤×•×– ×›×¤×•×™</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×¡×˜×˜×•×¡ ×—×•×§×™_××©×¤×•×– ×›×¤×•×™ ×“×—×•×£</th>\n",
       "      <th>×§×˜×’×•×¨×™×™×ª ×¡×˜×˜×•×¡ ×—×•×§×™_×’×•×¨××™× ××©×¤×˜×™×™×</th>\n",
       "      <th>××–×•×¨ ××•×¦×_××ª×™×•×¤×™×”</th>\n",
       "      <th>××–×•×¨ ××•×¦×_×‘×¨×™×ª ×”××•×¢×¦×•×ª</th>\n",
       "      <th>××–×•×¨ ××•×¦×_×™×©×¨××œ</th>\n",
       "      <th>×’×™×œ ×¢×œ×™×”</th>\n",
       "      <th>×—×–×¨ ×œ××©×¤×•×– ×ª×•×š ×—×•×“×©</th>\n",
       "      <th>×—×–×¨ ×œ××©×¤×•×– ×ª×•×š 3 ×—×•×“×©×™×</th>\n",
       "      <th>Month_January</th>\n",
       "      <th>Month_February</th>\n",
       "      <th>Month_March</th>\n",
       "      <th>Month_May</th>\n",
       "      <th>Month_June</th>\n",
       "      <th>Month_July</th>\n",
       "      <th>Month_August</th>\n",
       "      <th>Month_September</th>\n",
       "      <th>Month_October</th>\n",
       "      <th>Month_November</th>\n",
       "      <th>Month_December</th>\n",
       "      <th>Year_2021</th>\n",
       "      <th>Year_2022</th>\n",
       "      <th>Year_2023</th>\n",
       "      <th>Year_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>47098.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>77161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>81610.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>15554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>24408.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ××¡×¤×¨ ××˜×•×¤×œ ×¨× ×“×•××œ×™  ××¡×¤×¨ ××§×¨×” ××©×¤×•×– ×¨× ×“×•××œ×™  × ×§×‘×”  ×’×™×œ ××©×¤×•×–  \\\n",
       "0                 4.0                  47098.0   0.0   0.263158   \n",
       "1                24.0                  77161.0   0.0   0.473684   \n",
       "2                24.0                  81610.0   0.0   0.486842   \n",
       "3                24.0                  15554.0   0.0   0.486842   \n",
       "4                24.0                  24408.0   0.0   0.500000   \n",
       "\n",
       "   ××¦×‘ ××©×¤×—×ª×™_×’×¨×•×©/×”  ××¦×‘ ××©×¤×—×ª×™_× ×©×•×™/×  ××¦×‘ ××©×¤×—×ª×™_×¨×•×•×§/×”  \\\n",
       "0                0.0                0.0                1.0   \n",
       "1                0.0                0.0                1.0   \n",
       "2                0.0                0.0                1.0   \n",
       "3                0.0                0.0                1.0   \n",
       "4                0.0                0.0                1.0   \n",
       "\n",
       "   ×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_×‘×™×ª ×—×•×œ×™×  ×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_×’×•×¨××™ ××©×¤×˜ ×•×‘×™×˜×—×•×Ÿ  \\\n",
       "0                           0.0                                    0.0   \n",
       "1                           0.0                                    0.0   \n",
       "2                           0.0                                    0.0   \n",
       "3                           0.0                                    0.0   \n",
       "4                           0.0                                    0.0   \n",
       "\n",
       "   ×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_××•×¡×“ ×¨×¤×•××™ ××—×¨  ×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_×¤× ×™×” ×¢×¦××™×ª  \\\n",
       "0                                0.0                            1.0   \n",
       "1                                0.0                            0.0   \n",
       "2                                0.0                            0.0   \n",
       "3                                0.0                            0.0   \n",
       "4                                0.0                            0.0   \n",
       "\n",
       "   ×§×˜×’×•×¨×™×™×ª ×’×•×¨× ××¤× ×”_×¤×¡×™×›×™××˜×¨ ××—×•×–×™  ×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_×˜×™×¤×•×œ ××¨×¤××ª×™  \\\n",
       "0                                0.0                            1.0   \n",
       "1                                1.0                            1.0   \n",
       "2                                1.0                            1.0   \n",
       "3                                1.0                            0.0   \n",
       "4                                1.0                            1.0   \n",
       "\n",
       "   ×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_××•×¡×“×•×ª  ×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_××¨×¤××” ×¤×¡×™×›×™××˜×¨×™×ª  \\\n",
       "0                      0.0                                0.0   \n",
       "1                      0.0                                0.0   \n",
       "2                      0.0                                1.0   \n",
       "3                      0.0                                1.0   \n",
       "4                      0.0                                1.0   \n",
       "\n",
       "   ×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_×¨×•×¤× ××˜×¤×œ  ×§×˜×’×•×¨×™×™×ª ×”×•×¤× ×” ×œ_×¨×™×§  \\\n",
       "0                         0.0                   0.0   \n",
       "1                         0.0                   0.0   \n",
       "2                         0.0                   0.0   \n",
       "3                         0.0                   0.0   \n",
       "4                         0.0                   0.0   \n",
       "\n",
       "   ×§×˜×’×•×¨×™×™×ª ×¡×˜×˜×•×¡ ×—×•×§×™_××©×¤×•×– ×‘×”×¡×›××”  ×§×˜×’×•×¨×™×™×ª ×¡×˜×˜×•×¡ ×—×•×§×™_××©×¤×•×– ×›×¤×•×™  \\\n",
       "0                               1.0                             0.0   \n",
       "1                               1.0                             0.0   \n",
       "2                               0.0                             0.0   \n",
       "3                               0.0                             1.0   \n",
       "4                               0.0                             0.0   \n",
       "\n",
       "   ×§×˜×’×•×¨×™×™×ª ×¡×˜×˜×•×¡ ×—×•×§×™_××©×¤×•×– ×›×¤×•×™ ×“×—×•×£  ×§×˜×’×•×¨×™×™×ª ×¡×˜×˜×•×¡ ×—×•×§×™_×’×•×¨××™× ××©×¤×˜×™×™×  \\\n",
       "0                                  0.0                                 0.0   \n",
       "1                                  1.0                                 0.0   \n",
       "2                                  1.0                                 0.0   \n",
       "3                                  0.0                                 0.0   \n",
       "4                                  1.0                                 0.0   \n",
       "\n",
       "   ××–×•×¨ ××•×¦×_××ª×™×•×¤×™×”  ××–×•×¨ ××•×¦×_×‘×¨×™×ª ×”××•×¢×¦×•×ª  ××–×•×¨ ××•×¦×_×™×©×¨××œ  ×’×™×œ ×¢×œ×™×”  \\\n",
       "0                1.0                     0.0              0.0   0.21519   \n",
       "1                0.0                     0.0              1.0       NaN   \n",
       "2                0.0                     0.0              1.0       NaN   \n",
       "3                0.0                     0.0              1.0       NaN   \n",
       "4                0.0                     0.0              1.0       NaN   \n",
       "\n",
       "   ×—×–×¨ ×œ××©×¤×•×– ×ª×•×š ×—×•×“×©  ×—×–×¨ ×œ××©×¤×•×– ×ª×•×š 3 ×—×•×“×©×™×  Month_January  \\\n",
       "0                  0.0                      0.0              0   \n",
       "1                  0.0                      0.0              0   \n",
       "2                  0.0                      1.0              0   \n",
       "3                  0.0                      0.0              0   \n",
       "4                  0.0                      0.0              0   \n",
       "\n",
       "   Month_February  Month_March  Month_May  Month_June  Month_July  \\\n",
       "0               0            0          0           0           0   \n",
       "1               1            0          0           0           0   \n",
       "2               0            0          0           0           0   \n",
       "3               0            0          0           0           0   \n",
       "4               0            0          0           0           0   \n",
       "\n",
       "   Month_August  Month_September  Month_October  Month_November  \\\n",
       "0             0                1              0               0   \n",
       "1             0                0              0               0   \n",
       "2             0                0              0               0   \n",
       "3             1                0              0               0   \n",
       "4             1                0              0               0   \n",
       "\n",
       "   Month_December  Year_2021  Year_2022  Year_2023  Year_2024  \n",
       "0               0          0          0          1          0  \n",
       "1               0          0          0          0          0  \n",
       "2               0          0          0          0          0  \n",
       "3               0          0          0          0          0  \n",
       "4               0          1          0          0          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models/models_ran.ipynb\n",
    "\n",
    "# ğŸ“Œ ×©×œ×‘ 1: ×™×™×‘×•× ×¡×¤×¨×™×•×ª\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ğŸ“Œ ×©×œ×‘ 2: ×”×’×“×¨×•×ª ×‘×¡×™×¡\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style='whitegrid', palette='pastel')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# ğŸ“Œ ×©×œ×‘ 3: ×§×¨×™××ª ×”×§×•×‘×¥ ×”××¢×•×“×›×Ÿ ×‘×™×•×ª×¨\n",
    "notebook_path = os.getcwd() \n",
    "excel_path = os.path.join(notebook_path,\"..\", \n",
    " \"Excel_Updates\",\"Update 48 - Month Dummy Comparison\",\"month_year.xlsx\"\n",
    ")\n",
    "\n",
    "# ×‘×“×™×§×” ××” ×™×© ×‘×’×œ×™×•× ×•×ª\n",
    "xls = pd.ExcelFile(excel_path)\n",
    "print(\"Available sheets:\", xls.sheet_names)\n",
    "\n",
    "# ğŸ“Œ ×©×œ×‘ 4: ×˜×¢×Ÿ ××ª ×”×’×™×œ×™×•×Ÿ ×©×ª×¨×¦×” (×œ×“×•×’××” - ×’×™×œ×™×•×Ÿ ×¨××©×•×Ÿ)\n",
    "df = pd.read_excel(xls, sheet_name=0)  # ××¤×©×¨ ×’× sheet_name=\"×©×_×’×™×œ×™×•×Ÿ\"\n",
    "\n",
    "# ×ª×¦×•×’×” ×¨××©×•× ×™×ª ×©×œ ×”× ×ª×•× ×™×\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be2c992-0d02-4635-8d81-535088a0e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hadma\\anaconda3\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: torch in c:\\users\\hadma\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: python-docx in c:\\users\\hadma\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hadma\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6aced87752c4336b3e2e2721cc3da89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7510931e04ca459e89d8188103c9ce9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/299k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2457b691d74ffc877e1d63005460a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at avichr/heBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… embedding × ×©××¨ ×‘×”×¦×œ×—×” ×‘×§×•×‘×¥:\n",
      "C:\\Users\\hadma\\Desktop\\git\\DataFinalProjectDegree\\final_project\\NLP\\NLP_Updates\\Update_One_BertEmbedding\\bert_embedding.npy\n",
      "ğŸ“ ×¦×•×¨×ª ×”×•×•×§×˜×•×¨: (768,)\n"
     ]
    }
   ],
   "source": [
    "# --- ×©×œ×‘ 1: ×”×ª×§× ×ª ×¡×¤×¨×™×•×ª ---\n",
    "!pip install transformers torch python-docx\n",
    "\n",
    "# --- ×©×œ×‘ 2: ×™×™×‘×•× ×¡×¤×¨×™×•×ª ---\n",
    "import os\n",
    "import torch\n",
    "from docx import Document\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "# --- ×©×œ×‘ 3: ×”×’×“×¨×•×ª × ×ª×™×‘×™× ---\n",
    "project_root = os.getcwd()\n",
    "input_file = os.path.join(project_root, \"nlpTexts23Patients.docx\")  # ×”×§×•×‘×¥ ×”××§×•×¨×™ ×‘×ª×™×§×™×™×” ×”×¨××©×™×ª\n",
    "output_dir = os.path.join(project_root, \"NLP_Updates\", \"Update_One_BertEmbedding\")  # ×”×ª×™×§×™×™×” ×”×—×“×©×”\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)  # ×™×¦×™×¨×ª ×ª×™×§×™×™×” ×× ×œ× ×§×™×™××ª\n",
    "\n",
    "# --- ×©×œ×‘ 4: ×§×¨×™××ª ×”×˜×§×¡×˜ ××”×§×•×‘×¥ ---\n",
    "def read_docx(path):\n",
    "    doc = Document(path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        if para.text.strip() != \"\":\n",
    "            full_text.append(para.text.strip())\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "text = read_docx(input_file)\n",
    "\n",
    "# --- ×©×œ×‘ 5: ×˜×¢×™× ×ª ××•×“×œ heBERT ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"avichr/heBERT\")\n",
    "model = AutoModel.from_pretrained(\"avichr/heBERT\")\n",
    "\n",
    "# --- ×©×œ×‘ 6: ×”××¨×ª ×”×˜×§×¡×˜ ×œ×•×•×§×˜×•×¨ ---\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "embedding_vector = get_bert_embedding(text)\n",
    "\n",
    "# --- ×©×œ×‘ 7: ×©××™×¨×ª ×”×•×•×§×˜×•×¨ ×›×§×•×‘×¥ Numpy ---\n",
    "output_path = os.path.join(output_dir, \"bert_embedding.npy\")\n",
    "np.save(output_path, embedding_vector)\n",
    "\n",
    "print(f\"âœ… embedding × ×©××¨ ×‘×”×¦×œ×—×” ×‘×§×•×‘×¥:\\n{output_path}\")\n",
    "print(\"ğŸ“ ×¦×•×¨×ª ×”×•×•×§×˜×•×¨:\", embedding_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc2bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ×¦×•×¨×ª ×”×•×•×§×˜×•×¨: (768,)\n",
      "ğŸ”¢ ×›××” ×¢×¨×›×™× ×¨××©×•× ×™×: [-0.19961533 -1.0052215  -0.30320576  0.2110568   0.14718096 -0.3588538\n",
      " -0.6137744   0.20024087 -0.25652686 -0.04816744]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ×˜×•×¢× ×™× ××ª ×”×§×•×‘×¥\n",
    "embedding = np.load(\"NLP_Updates/Update_One_BertEmbedding/bert_embedding.npy\")\n",
    "\n",
    "# ××¦×™×’×™× ×§×¦×ª ××™×“×¢\n",
    "print(\"ğŸ“ ×¦×•×¨×ª ×”×•×•×§×˜×•×¨:\", embedding.shape)\n",
    "print(\"ğŸ”¢ ×›××” ×¢×¨×›×™× ×¨××©×•× ×™×:\", embedding[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763b69a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0-rc1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.31)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e0bf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5d2c12d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ×¤×ª×¨×•×Ÿ ×”×‘×¢×™×”: ×œ×”×›×¨×™×— ×œ×”×©×ª××© ×‘Ö¾PyTorch ×‘×œ×‘×“\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m qa \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion-answering\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepset/roberta-base-squad2\u001b[39m\u001b[38;5;124m\"\u001b[39m, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# ×ª×¨×’×•×\u001b[39;00m\n\u001b[0;32m      8\u001b[0m translator \u001b[38;5;241m=\u001b[39m Translator()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:807\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    806\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 807\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    808\u001b[0m         model,\n\u001b[0;32m    809\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    810\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    811\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    812\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    815\u001b[0m     )\n\u001b[0;32m    817\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    818\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:219\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from googletrans import Translator\n",
    "\n",
    "# ×¤×ª×¨×•×Ÿ ×”×‘×¢×™×”: ×œ×”×›×¨×™×— ×œ×”×©×ª××© ×‘Ö¾PyTorch ×‘×œ×‘×“\n",
    "qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", framework=\"pt\")\n",
    "\n",
    "# ×ª×¨×’×•×\n",
    "translator = Translator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f19be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for httpx==0.13.3 from https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for hstspreload from https://files.pythonhosted.org/packages/76/c3/87beb45b57c9c418d32aa773a9d0adcf3b91422b7ad1fcc46f9d2b691eed/hstspreload-2025.1.1-py3-none-any.whl.metadata\n",
      "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for chardet==3.* from https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for idna==2.* from https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl.metadata\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for rfc3986<2,>=1.3 from https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for httpcore==0.9.* from https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for h11<0.10,>=0.8 from https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for h2==3.* from https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for hyperframe<6,>=5.2.0 from https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Obtaining dependency information for hpack<4,>=3.0 from https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.1 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 30.7/55.1 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 55.1/55.1 kB 954.5 kB/s eta 0:00:00\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 30.7/133.4 kB 1.4 MB/s eta 0:00:01\n",
      "   ----------------- --------------------- 61.4/133.4 kB 825.8 kB/s eta 0:00:01\n",
      "   -------------------------- ------------ 92.2/133.4 kB 880.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 133.4/133.4 kB 879.4 kB/s eta 0:00:00\n",
      "Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 30.7/58.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 58.8/58.8 kB 783.4 kB/s eta 0:00:00\n",
      "Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.0 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 41.0/65.0 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 65.0/65.0 kB 883.9 kB/s eta 0:00:00\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.3 MB 1.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.1/1.3 MB 1.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 958.1 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.3 MB 1.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.3 MB 1.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.4/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.3 MB 972.0 kB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.5/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.3 MB 994.0 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.6/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.7/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.7/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.8/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.9/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.0/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.1/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.1/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.3/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.6/53.6 kB 922.7 kB/s eta 0:00:00\n",
      "Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17461 sha256=22cce5780a7ab7b779522513a13e517e13343489b508f72d1e2a6a7f6f3a70b1\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\39\\17\\6f\\66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "# ×ª×¨×’×•× ×œ×× ×’×œ×™×ª - ×¢×“×›×•×Ÿ ×’×¨×¡×” ×œ×¤×™×™×ª×•×Ÿ\n",
    "import sys\n",
    "!{sys.executable} -m pip install googletrans==4.0.0-rc1\n",
    "\n",
    "from googletrans import Translator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed05a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "×”×˜×§×¡×˜ ×©×ª×•×¨×’×: The patient reports suicidal thoughts.Notal Ciprlex.Is not smoking.\n"
     ]
    }
   ],
   "source": [
    "#×‘×“×™×§×” ×©×”×’×¨×¡×” ×©×œ ×¤×™×™×ª×•×Ÿ ×¢×•×‘×“×ª\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "text_he = \"×”××˜×•×¤×œ ××“×•×•×— ×¢×œ ××—×©×‘×•×ª ××•×‘×“× ×™×•×ª. × ×•×˜×œ ×¦×™×¤×¨×œ×§×¡. ××™× ×• ××¢×©×Ÿ.\"\n",
    "text_en = translator.translate(text_he, src='he', dest='en').text\n",
    "\n",
    "print(\"×”×˜×§×¡×˜ ×©×ª×•×¨×’×:\", text_en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9095d91",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ×©×œ×‘ 1: ×”×›× ×ª ×ª×¨×’×•× ×•××•×“×œ ×©××œ×”-×ª×©×•×‘×”\u001b[39;00m\n\u001b[0;32m      5\u001b[0m translator \u001b[38;5;241m=\u001b[39m Translator()\n\u001b[1;32m----> 6\u001b[0m qa \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion-answering\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepset/roberta-base-squad2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# ×©×œ×‘ 2: ×”×’×“×¨×ª ×”×©××œ×•×ª\u001b[39;00m\n\u001b[0;32m      9\u001b[0m questions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_suicidal_thoughts\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoes the patient have suicidal thoughts?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoes the patient show aggression?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_violent_behavior\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid the patient behave violently?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:807\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    806\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 807\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    808\u001b[0m         model,\n\u001b[0;32m    809\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    810\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    811\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    812\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    815\u001b[0m     )\n\u001b[0;32m    817\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    818\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:219\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "from transformers import pipeline\n",
    "\n",
    "# ×©×œ×‘ 1: ×”×›× ×ª ×ª×¨×’×•× ×•××•×“×œ ×©××œ×”-×ª×©×•×‘×”\n",
    "translator = Translator()\n",
    "qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# ×©×œ×‘ 2: ×”×’×“×¨×ª ×”×©××œ×•×ª\n",
    "questions = {\n",
    "    \"has_suicidal_thoughts\": \"Does the patient have suicidal thoughts?\",\n",
    "    \"aggression\": \"Does the patient show aggression?\",\n",
    "    \"takes_medication\": \"Is the patient taking psychiatric medication?\",\n",
    "    \"is_oriented\": \"Is the patient oriented?\",\n",
    "    \"has_violent_behavior\": \"Did the patient behave violently?\"\n",
    "}\n",
    "\n",
    "# ×©×œ×‘ 3: ×”×¤×•× ×§×¦×™×”\n",
    "def analyze_medical_text(text_he):\n",
    "    # ×ª×¨×’×•× ×”×˜×§×¡×˜ ×œ×¢×‘×¨×™×ª\n",
    "    text_en = translator.translate(text_he, src='he', dest='en').text\n",
    "\n",
    "    answers = {}\n",
    "    for key, q in questions.items():\n",
    "        try:\n",
    "            result = qa(question=f\"Please answer yes or no: {q}\", context=text_en)\n",
    "            answer = result['answer'].lower()\n",
    "            score = result['score']\n",
    "\n",
    "            if any(word in answer for word in [\"yes\", \"does\", \"is\", \"true\"]):\n",
    "                answers[key] = \"yes\"\n",
    "            elif any(word in answer for word in [\"no\", \"not\", \"false\"]):\n",
    "                answers[key] = \"no\"\n",
    "            else:\n",
    "                answers[key] = \"unknown\"\n",
    "        except Exception as e:\n",
    "            answers[key] = f\"error: {e}\"\n",
    "\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd737af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
 73a0729d655d7120f75d44953fa5abe621111133
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
